{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyMT4Ah4VIZLm4j1gkjl1LQ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rSwRkt8Wd1YV"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","from scipy.stats import zscore\n","from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n","from sklearn.svm import SVC, OneClassSVM\n","from sklearn.covariance import EllipticEnvelope\n","from sklearn.ensemble import IsolationForest, VotingClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","\n","\n","import os\n","\n","target_column = 'Label'\n","\n","# Specify the path to your CSV file\n","csv_file_path = r\"C:\\Users\\abett\\Downloads\\csci\\combined_file.csv\"\n","\n","# Read the CSV file into a Pandas DataFrame\n","tf_df = pd.read_csv(csv_file_path)\n","\n","# Display the first few rows of the DataFrame\n","print(tf_df.head())\n"]},{"cell_type":"code","source":["# Get the columns of the DataFrame\n","columns = tf_df.columns\n","\n","# Display the columns\n","print(columns)"],"metadata":{"id":"AjqYqgowkBv6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display basic information about the dataset\n","tf_df.info()\n"],"metadata":{"id":"zmLPkvLjkSRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Display summary statistics for numerical columns\n","print(tf_df.describe())\n"],"metadata":{"id":"aFW9C-LIkeht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check for missing values in each column\n","print(tf_df.isnull().sum())\n"],"metadata":{"id":"h8-1Eddnk35H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Getting the count of each type of attack\n","label_counts = tf_df[' Label'].value_counts()\n","print(label_counts)\n"],"metadata":{"id":"EI6FA8stmqSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Converting 'int64' and 'float64' to 'int32' and 'float32' to save memory\n","# Identify integer and float columns\n","integer_columns = tf_df.select_dtypes(include=['int64']).columns\n","float_columns = tf_df.select_dtypes(include=['float64']).columns\n","\n","# Convert integer columns to int32\n","tf_df[integer_columns] = tf_df[integer_columns].astype('int32')\n","\n","# Convert float columns to float32\n","tf_df[float_columns] = tf_df[float_columns].astype('float32')\n","\n","# Display updated DataFrame information\n","tf_df.info()\n"],"metadata":{"id":"vRrVSJrPoYMw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize the distribution of the target variable 'Label'\n","plt.figure(figsize=(10, 6))\n","sns.countplot(x=' Label', data=tf_df, order=tf_df[' Label'].value_counts().index)\n","plt.title('Distribution of Attack Types')\n","plt.xticks(rotation=45)\n","plt.show()\n","\n"],"metadata":{"id":"fZFyE2nOtVRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualize the distribution of a specific feature (e.g., 'Flow Duration') for each attack type\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x=' Label', y=' Flow Duration', data=tf_df)\n","plt.title('Distribution of Flow Duration for Different Attack Types')\n","plt.xticks(rotation=45)\n","plt.show()\n","\n","\n"],"metadata":{"id":"OQGOhhwMMs8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Replace 'your_file.csv' with the actual file path or URL\n","file_path = r\"C:\\Users\\abett\\Downloads\\csci\\tdf.csv\"\n","\n","# Read the CSV file into a DataFrame\n","tdf = pd.read_csv(file_path)\n","\n","# Display the first few rows of the DataFrame to verify the import\n","print(tdf.head(20))\n"],"metadata":{"id":"AcKlwnpGPUwz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Concatenate vertically\n","cdf = pd.concat([tf_df, tdf], ignore_index=True)\n","\n","# Display the combined DataFrame\n","print(cdf)"],"metadata":{"id":"l7JLJuWmfzWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cdf.shape)\n"],"metadata":{"id":"Yga9rse8xtnp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cdf.isnull().sum())\n"],"metadata":{"id":"d1kByFEPxxWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cdf = cdf.drop(['ipv4', 'Label', 'date'], axis=1)\n"],"metadata":{"id":"VFa0QfIeyQt5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(cdf.isnull().sum())\n","\n","cdf.fillna(22, inplace=True)  # Replace 'value' with the imputation value\n"],"metadata":{"id":"Nwo2alLZzWZU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Perform label encoding\n","label_encoder = LabelEncoder()\n","cdf['Label_encoded'] = label_encoder.fit_transform(cdf[' Label'])\n","\n","# Handle missing values using SimpleImputer\n","pipeline = make_pipeline(SimpleImputer(strategy='mean'), RandomForestClassifier(random_state=42))\n","\n","\n","# Define the features (X) and target variable (y)\n","X = cdf.drop([' Label', 'Label_encoded'], axis=1)\n","y = cdf['Label_encoded']\n","\n","# Perform train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Signature-based detection models\n","signature_models = [\n","    ('RandomForest', RandomForestClassifier(random_state=42)),\n","    ('GradientBoosting', GradientBoostingClassifier(random_state=42)),\n","    ('DecisionTree', DecisionTreeClassifier(random_state=42)),\n","    ('KNeighbors', KNeighborsClassifier()),\n","    ('SVM', SVC(probability=True)),\n","]\n","\n","# Anomaly-based detection models\n","anomaly_models = [\n","    ('OneClassSVM', OneClassSVM()),\n","    ('IsolationForest', IsolationForest(random_state=42)),\n","    ('EllipticEnvelope', EllipticEnvelope()),\n","    ('LocalOutlierFactor', LocalOutlierFactor()),\n","    # Add more anomaly-based models as needed\n","]\n","\n","# Hybrid model (Voting Classifier)\n","hybrid_model = VotingClassifier(estimators=signature_models + anomaly_models, voting='soft')\n","\n","# Train and evaluate signature-based models\n","for name, model in signature_models:\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    print(f\"\\n{name}:\\n{classification_report(y_test, y_pred)}\")\n","\n","# Train and evaluate anomaly-based models\n","for name, model in anomaly_models:\n","    model.fit(X_train)\n","    y_pred = model.predict(X_test)\n","    y_pred[y_pred == 1] = 0  # Convert normal class to 0\n","    y_pred[y_pred == -1] = 1  # Convert anomaly class to 1\n","    print(f\"\\n{name}:\\n{classification_report(y_test, y_pred)}\")\n","\n","# Train and evaluate hybrid model\n","hybrid_model.fit(X_train, y_train)\n","y_pred_hybrid = hybrid_model.predict(X_test)\n","print(f\"\\nHybrid Model:\\n{classification_report(y_test, y_pred_hybrid)}\")"],"metadata":{"id":"CU2plwkzyTzv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lfoaai4Lz9Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert 'float64' to 'float32' and 'int64' to 'int32'\n","float_columns = cdf.select_dtypes(include=['float64']).columns\n","int_columns = cdf.select_dtypes(include=['int64']).columns\n","cdf[float_columns] = cdf[float_columns].astype('float32')\n","cdf[int_columns] = cdf[int_columns].astype('int32')\n"],"metadata":{"id":"dA0f1aElhHaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Replace 'your_dataset.csv' with the actual path to your CSV file\n","file_path = r\"C:\\Users\\abett\\Downloads\\csci\\tdf.csv\"\n","\n","# Read the CSV file into a Pandas DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Display the first few rows of the DataFrame to verify the import\n","print(df.head())\n","\n","\n","import requests\n","import pandas as pd\n","import json\n","\n","# Assuming your DataFrame is named 'df' and the IPv4 addresses are in the 'ipv4' column\n","ipv4_column = df['ipv4']\n","\n","# AlienVault OTX API configuration\n","api_key = '7eeddf89313553770b1cb75c392cd7eef85a514e72eedcb61b79be02f11da5bb'\n","otx_api_url = 'https://otx.alienvault.com/api/v1/indicators/IPv4/'\n","\n","for ipv4_address in ipv4_column:\n","    # Make a GET request to the AlienVault OTX API\n","    response = requests.get(otx_api_url + ipv4_address, headers={'X-OTX-API-KEY': api_key})\n","\n","    # Check if the request was successful (status code 200)\n","    if response.status_code == 200:\n","        # Beautify and print the JSON response\n","        formatted_response = json.dumps(response.json(), indent=2)\n","        print(f\"IPv4 Address: {ipv4_address}\")\n","        print(\"OTX API Response:\")\n","        print(formatted_response)\n","        print(\"\\n\")\n","    else:\n","        print(f\"Error for IPv4 Address {ipv4_address}. Status Code: {response.status_code}\")\n","\n"],"metadata":{"id":"WL3jdFSXz-eS"},"execution_count":null,"outputs":[]}]}